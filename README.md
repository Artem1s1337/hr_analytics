<p align="center">
  <h1>ETL-пайплайн для мониторинга вакансий через API hh.ru в аналитике и ML с использованием PostgreSQL, Power BI</h1>
</p>

# Оглавление
1. [Бизнес-контекст](#Бизнес-контекст)
2. [Архитектура](#Архитектура)
3. [Использование](#Использование)

## Бизнес-контекст
Проект представляет собой ETL-пайплайн, который помогает новичкам в аналитике и ML за 1.5 часа получить основную информацию о вакансиях на hh.ru в виде BI-отчёта:
- распределение зарплат
- рапределение по грейдам и городам
- динамика публикации вакансий
- ключевые навыки на определенную позицию --> актуальный стек для изучения
- форматы работы
- топ работодателей

## Архитектура
```
hr_analytics/
├── dash/
│   └── vacancies_dashboard.pbix    # Дашборд Power BI по вакансиям
├── data/
│   ├── db_data/                    # Данные для загрузки в БД
│   ├── processed/                  # Обработанные датасеты
│   └── raw/                        # Сырые данные
├── images/                         # Графики
├── notebooks/                      # Ноутбуки
├── sql/                            # SQL-скрипты и ERD
├── src/                            # Исходный код
├── .pre-commit-config.yaml         # Хуки форматирования/линтинга перед коммитом
├── README.md                       # Описание проекта и инструкции по запуску
├── poetry.lock                     # Зафиксированные версии зависимостей Poetry
└── pyproject.toml                  # Конфигурация Poetry и дев-инструментов
```

## Использование
```markdown

```bash
# Клонируйте репозиторий
git clone <your-repository-url>
cd hr_analytics

# Установите зависимости
poetry install

# Если Poetry не установлен, установите его, затем вернитесь ко второму шагу
pip poetry install

# Запустите по порядку скрипты
# Лимит API на глубину запроса (пагинацию): <= 2000 вакансий, иными словами 20 страниц по 100 вакансий на страницу (это максимум)
poetry run python extract.py
poetry run python transform.py
poetry run python load.py  # предварительно создайте БД на PostgreSQL
```
Важное замечание по работе с БД: внутри скрипта `load.py` импортируется модуль `db_config.py` с данными для подключения к БД. Вам необходимо создать собственный конфиг формата
```
DBNAME = "Название БД"
USER = "Имя пользователя"  # по умолчанию postgres
PASSWORD = "Пароль"
HOST = "Хост"  # по умолчанию localhost
PORT = "Порт"  # (целое число), по умолчанию 5432
```
Далее в БД необходимо запустить скрипт ERD: `erd_creation_query.sql` из папки `/sql` чтобы установить отношения между таблицами. Вот как это должно выглядеть:
<img width="1314" height="882" alt="erd_schema" src="https://github.com/user-attachments/assets/9db1515e-de40-4e5b-9bdd-c13fd664366e" />
Последним шагом будет запуск `vacancies_dashboard.pbix` из папки `/dash` и интеграция в него таблиц. В итоге вы получите следующий дашборд:
<img width="1302" height="731" alt="{C757EEE8-1B0B-424F-9A72-F09C0798F2A0}" src="https://github.com/user-attachments/assets/52d239f2-d86c-44a7-9f82-e9142b65f85a" />
