<p align="center">
  <h1>ETL-пайплайн для мониторинга вакансий через API hh.ru в аналитике и ML с использованием PostgreSQL, Power BI</h1>
</p>

# Оглавление
1. [Бизнес-контекст](#Бизнес-контекст)
2. [Данные](#Данные)
3. [Этапы](#Этапы)
4. [Использование](#Использование)

## Бизнес-контекст
Ключевая задача проекта - разработка аналитического инструмента для новичков в ML и анализе данных в топ-10 городах Россию по населению с использованием `API hh.ru`. Инструмент помогает новичкам получить за 1.5 часа основную информацию о вакансиях на разные роли на основе BI-отчёта:
- медианная зарплата
- разница медианных зарплат по грейдам
- разница медианных зарплат по опыту
- ключевые навыки на определенную позицию --> актуальный стек для изучения
- роли в аналитике и ML
- различные распределения по городам

## Данные
Cобранные данные содержат:
- `id`: уникальный идентификатор вакансии
- `name`: название вакансии
- `salary_from`: нижняя граница зарплаты
- `salary_to`: верхняя граница зарплаты
- `currency`: валюта
- `key_skills`: ключевые навыки
- `role`: позиция/роль
- `city`: город
- `date`: дата публикации
- `fmt`: формат работы
- `exp`: опыт работы
- `employer`: работодатель

Дополнительные колонки:
- `mid_salary`: медианная зарплата (вычисляемая
- `grade`: грейд вакансии (на основе опыта)

## Этапы проекта
1. Написать парсер для сбора данных (Exctract)
2. Написать скрипт для обработки данных (Transform)
3. Провести EDA
4. Подготовить данные к загрузке в БД (таблица фактов и таблицы измерений)
5. Загрузить в БД, настроить связи и ERD
6. Интегрировать данные в дашборд, настроив визуализации и связи
7. Настроить зависимости и версии

## Использование
```markdown

```bash
# Клонируйте репозиторий
git clone <your-repository-url>
cd hr_analytics

# Установите зависимости
poetry install

# Если Poetry не установлен, установите его, затем вернитесь ко второму шагу
pip poetry install

# Запустите по порядку скрипты
poetry run python extract.py
poetry run python transform.py
poetry run python load.py  # предварительно создайте БД на PostgreSQL
```
Далее в БД необходимо запустить скрипт ERD: `erd_creation_query.sql` из папки `/sql` чтобы установить отношения между таблицами. Вот как это должно выглядеть:
<img width="1314" height="882" alt="erd_schema" src="https://github.com/user-attachments/assets/9db1515e-de40-4e5b-9bdd-c13fd664366e" />
Последним шагом будет запуск `vacancies_dashboard.pbix` из папки `/dash` и интеграция в него таблиц

## Ограничения
Основное ограничение - лимит API на глубину запроса (пагинацию): <= 2000 вакансий, иными словами 20 страниц по 100 вакансий на страницу (это максимум):
<img width="924" height="338" alt="image" src="https://github.com/user-attachments/assets/29c88f84-a2d3-4d09-9624-ad6ba36412be" />
